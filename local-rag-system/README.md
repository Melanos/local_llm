# Local RAG System

A professional local Retrieval-Augmented Generation (RAG) system that processes documents and images for AI-powered question answering.

## ğŸš€ Features

- **ğŸ“„ Document Processing**: Extract and index content from Word documents (.docx)
- **ğŸ–¼ï¸ Image Analysis**: Analyze images using InstructBLIP vision model
- **ğŸ¤– AI Chat**: Interactive chatbot with conversation history
- **ğŸŒ Modern Web UI**: Beautiful web interface with real-time chat
- **ğŸ” Semantic Search**: Find relevant content using vector embeddings
- **ğŸ’¾ Local Storage**: All data stays on your machine
- **ğŸ¯ Smart Relevance**: Configurable relevance thresholds for better results

## ğŸ“ Project Structure

```
local-rag-system/
â”œâ”€â”€ config.py              # Project configuration
â”œâ”€â”€ start_web_ui.bat        # Start web interface (NEW!)
â”œâ”€â”€ start_chat.bat          # Start terminal chat
â”œâ”€â”€ train_documents.py      # Document training script
â”œâ”€â”€ train_images.py         # Image training script
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ README.md              # This file
â”œâ”€â”€ web_ui/                # Modern web interface
â”‚   â”œâ”€â”€ app.py             # Flask web application
â”‚   â”œâ”€â”€ templates/         # HTML templates
â”‚   â””â”€â”€ static/            # CSS, JS, assets
â”œâ”€â”€ data/                  # Data directories
â”‚   â”œâ”€â”€ core/              # Core functionality
â”‚   â”‚   â”œâ”€â”€ rag_engine.py  # RAG database operations
â”‚   â”‚   â””â”€â”€ chat_interface.py # Chat interface
â”‚   â”œâ”€â”€ training/          # Training modules
â”‚   â”‚   â”œâ”€â”€ document_trainer.py # Document processing
â”‚   â”‚   â””â”€â”€ image_trainer.py    # Image analysis
â”‚   â””â”€â”€ utils/             # Utility functions
â”‚       â””â”€â”€ database_utils.py   # Database utilities
â”œâ”€â”€ data/                  # Data directories
â”‚   â”œâ”€â”€ documents/         # Place .docx files here
â”‚   â”œâ”€â”€ images/            # Place image files here
â”‚   â””â”€â”€ analysis_results/  # Generated analysis files
â”œâ”€â”€ database/              # Vector database storage
â””â”€â”€ docs/                  # Documentation
```

## ï¿½ Quick Start (Windows)

### Easy Way - Double-click these files:
- **`start_chat.bat`** - Start the chatbot  
- **`train_docs.bat`** - Train on documents
- **`train_imgs.bat`** - Train on images

### Manual Way:
1. **Activate environment**: 
   ```cmd
   C:\local-rag\local-rag-env\Scripts\Activate.bat
   cd "C:\Scripts for LLM\local-rag-system"
   ```

2. **Train your data**:
   ```cmd
   python train_documents.py
   python train_images.py
   ```

3. **Start chatting**:
   ```cmd
   python chat.py
   ```

## ğŸ“š Usage

### ğŸŒ **Option 1: Modern Web UI (Recommended)**

1. **Double-click `start_web_ui.bat`**
2. **Open browser to: http://localhost:5000**
3. **Use the beautiful web interface to:**
   - ğŸ’¬ Chat with AI in real-time
   - ğŸ“š Train documents and images
   - ğŸ” Search and manage database
   - âš™ï¸ Adjust settings

### ğŸ’» **Option 2: Command Line**

### 1. Add Your Data

**Documents**: Place `.docx` files in `data/documents/`
```bash
# Train on documents
python train_documents.py
```

**Images**: Place image files in `data/images/`
```bash
# Train on images  
python train_images.py
```

### 2. Start Chatting

```bash
# Start the chatbot
python chat.py
```

### 3. Chat Commands

- `/stats` - Show database statistics
- `/clear_chat` - Clear conversation history  
- `/quit` - Exit the chatbot

## ğŸ¯ Configuration

Edit `config.py` to customize:

- **Models**: Change AI models used
- **Paths**: Modify data directories
- **Chunking**: Adjust text chunking parameters
- **Relevance**: Fine-tune search thresholds

```python
DEFAULT_CONFIG = {
    "models": {
        "chat_model": "llama3.2",
        "embedding_model": "nomic-embed-text", 
        "vision_model": "Salesforce/instructblip-vicuna-7b"
    },
    "relevance": {
        "search_threshold": 0.3,  # Lower = broader search
        "chat_threshold": 0.2     # Lower = more results
    }
}
```

## ğŸ”§ Advanced Usage

### Database Utilities

```bash
# Show database stats
python -m src.utils.database_utils --stats

# Search for specific content
python -m src.utils.database_utils --search "technical skills"

# List all sources
python -m src.utils.database_utils --sources
```

### Custom Training

```python
from src.training.document_trainer import DocumentTrainer
from src.training.image_trainer import ImageTrainer

# Train on specific directory
doc_trainer = DocumentTrainer()
doc_trainer.train_documents(Path("path/to/docs"))

# Analyze specific image
img_trainer = ImageTrainer()
img_trainer.process_image(Path("path/to/image.jpg"))
```

## ğŸ¨ Supported Formats

**Documents**:
- `.docx` (Microsoft Word)

**Images**:
- `.jpg`, `.jpeg`, `.png`, `.bmp`, `.tiff`, `.webp`

## ğŸš¨ Troubleshooting

### Common Issues

1. **Ollama Connection Error**
   - Ensure Ollama is running: `ollama serve`
   - Check if models are installed: `ollama list`

2. **CUDA Memory Issues**
   - Reduce batch size in image processing
   - Use CPU instead: edit config to use `"cpu"`

3. **Poor Search Results**
   - Lower relevance thresholds in `config.py`
   - Add more specific keywords to queries
   - Check database content with `--stats`

4. **Import Errors**
   - Ensure virtual environment is activated
   - Install missing packages: `pip install -r requirements.txt`

## ğŸ“ˆ Performance Tips

- **Better Relevance**: Use specific, detailed questions
- **Faster Processing**: Use GPU for image analysis
- **Memory Management**: Process large datasets in batches
- **Query Optimization**: Start broad, then ask specific follow-ups

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- **Ollama** - Local LLM hosting
- **ChromaDB** - Vector database
- **InstructBLIP** - Image analysis model
- **Transformers** - AI model library
